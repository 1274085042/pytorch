usage: torchbench.py [-h] [--filter FILTER] [--exclude EXCLUDE]
                     [--exclude-exact EXCLUDE_EXACT]
                     [--total-partitions {1,2,3,4,5,6,7,8,9}]
                     [--partition-id PARTITION_ID] [--devices DEVICES]
                     [--device-index DEVICE_INDEX] [--repeat REPEAT]
                     [--iterations-per-run ITERATIONS_PER_RUN]
                     [--randomize-input] [--threads THREADS] [--nopython]
                     [--no-skip] [--prims-nvfuser] [--dump-raw-metrics]
                     [--log-operator-inputs] [--channels-last]
                     [--batch-size BATCH_SIZE] [--iterations ITERATIONS]
                     [--batch-size-file BATCH_SIZE_FILE] [--cosine] [--ci]
                     [--dynamic-ci-skips-only] [--dashboard]
                     [--skip-fp64-check] [--fast] [--only ONLY] [--ddp]
                     [--fsdp] [--no-optimize-ddp]
                     [--distributed-master-port DISTRIBUTED_MASTER_PORT]
                     [--dynamic-shapes] [--dynamic-batch-only]
                     [--specialize-int] [--use-eval-mode]
                     [--skip-accuracy-check] [--generate-aot-autograd-stats]
                     [--inductor-settings] [--suppress-errors]
                     [--output OUTPUT] [--output-directory OUTPUT_DIRECTORY]
                     [--part PART] [--export-profiler-trace]
                     [--profiler-trace-name PROFILER_TRACE_NAME]
                     [--diff-branch DIFF_BRANCH] [--tag TAG] [--explain]
                     [--stats] [--cold-start-latency] [--disable-cudagraphs]
                     [--inductor-compile-mode INDUCTOR_COMPILE_MODE]
                     [--print-graph-breaks] [--trace-on-xla]
                     [--xla-tolerance XLA_TOLERANCE] [--collect-outputs]
                     [--timing] [--progress] [--timeout TIMEOUT]
                     [--per_process_memory_fraction PER_PROCESS_MEMORY_FRACTION]
                     [--nnc] [--float16 | --bfloat16 | --float32 | --amp]
                     [--verbose | --quiet]
                     [--coverage | --overhead | --speedup-dynamo-ts | --speedup-fx2trt | --speedup-fx2trt-fp16 | --print-fx | --print-aten-ops | --inductor | --backend {aot_eager,aot_eager_decomp_partition,aot_torchxla_trace_once,aot_torchxla_trivial,aot_ts,aot_ts_nvfuser,cudagraphs,dynamo_accuracy_minifier_backend,dynamo_minifier_backend,eager,inductor,ipex,nvprims_aten,nvprims_nvfuser,onnxrt,torchxla_trace_once,torchxla_trivial,ts,tvm} | --nothing | --log-conv-args | --recompile-profiler | --find-batch-sizes]
                     (--accuracy | --performance) (--training | --inference)
torchbench.py: error: argument --inference: not allowed with argument --training
